{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff884a10-6c69-4cd4-bec7-28c8c4081e2a",
   "metadata": {},
   "source": [
    "## Finetuning a Large Language Model\n",
    "##### Step by step guide to performing Low Rank Adaptation For Finetuning (LoRA) of LLMs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9bd8d7-7ff8-4b8e-9b4f-06f08f362eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = !python3 -m pip install --upgrade pip\n",
    "_ = !pip install accelerate -U\n",
    "_ = !pip install peft\n",
    "_ = !pip install datasets\n",
    "_ = !pip install transformers[torch]\n",
    "_ = !pip install bitsandbytes\n",
    "_ = !pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eb4afe-5881-49cb-98b2-3ae1ba1b5133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import string\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "import torch\n",
    "import transformers\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fea9dab-d0e5-47e7-ac04-c2119f2ae0c2",
   "metadata": {},
   "source": [
    "### Import a LLM from HuggingFace\n",
    "\n",
    "For more info about the used model: https://huggingface.co/Salesforce/codegen-350M-mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b6f54c-234e-4c58-a48a-8f512b3976a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"Salesforce/codegen-350M-mono\"\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8390c4a5-09a8-443e-b4cd-55eada9f07d7",
   "metadata": {},
   "source": [
    "### Run an example prediction/inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a44c14-b1a3-462a-8668-5322c5a77dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"def hello_world():\"\n",
    "\n",
    "completion = model.generate(**tokenizer(text, return_tensors=\"pt\").to(\"cuda\"))\n",
    "\n",
    "print(tokenizer.decode(completion[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f9d73d-5b47-4065-bd20-c0a52bf89aeb",
   "metadata": {},
   "source": [
    "### Prepare model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8579a15a-80dc-472f-a043-734f07315f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRADIENT_CHECKPOINTING = False\n",
    "PER_DEVICE_TRAIN_BATCH_SIZE = 1\n",
    "WARMUP_STEPS = 0\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-5\n",
    "R = 32\n",
    "LORA_ALPHA = R\n",
    "LORA_DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c93834-5209-4773-a2e3-aebfaf33f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_target_modules(model) -> List[str]:\n",
    "    \"\"\"\n",
    "    Identify linear layers in the model and return as list.\n",
    "    \"\"\"\n",
    "    layers = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if \"Linear\" in str(type(module)):\n",
    "            layer_type = name.split('.')[-1]\n",
    "            layers.add(layer_type)\n",
    "\n",
    "    return list(layers)\n",
    "\n",
    "target_modules = find_target_modules(model)\n",
    "target_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9063af9-ce6d-4101-8d0a-8cd54746be71",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=\"Causal_LM\", inference_mode=False, r=R, lora_alpha=LORA_ALPHA, lora_dropout=0.1, target_modules=target_modules\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d5054e-fd5e-4a65-91cb-4bbbaca79060",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65116dd-bf9c-474d-ab87-8fa93ce215d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d52980d-f3da-454d-acc7-35020f9e11fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = string.ascii_letters\n",
    "\n",
    "prompts = []\n",
    "length = 100\n",
    "for i in range(3):\n",
    "    random_string = ''.join(random.choice(letters) for i in range(length))\n",
    "    prompts.append(\"def hello_world():\" + random_string)\n",
    "\n",
    "data = [{\"text\": x} for x in prompts]\n",
    "dataset = Dataset.from_dict({\"text\": [item[\"text\"] for item in data[:]]})\n",
    "tokenized_dataset = dataset.map(lambda x : tokenizer(x[\"text\"]), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b798df-b723-4c72-bb61-8a838c4acf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = transformers.TrainingArguments(\n",
    "    per_device_train_batch_size=PER_DEVICE_TRAIN_BATCH_SIZE,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    logging_steps=100,\n",
    "    save_total_limit=1,\n",
    "    output_dir=os.path.join('.', datetime.now().strftime(\"%Y%m%d%H%M%S\")),\n",
    "    gradient_checkpointing=GRADIENT_CHECKPOINTING\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236c5dc8-110a-459a-ae63-11c963a0bacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    args=train_args,\n",
    "    callbacks=[],\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(\n",
    "        tokenizer, mlm=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69897cf0-8547-4e10-a5f8-c952e36c672e",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a89252-06ec-44bf-afd2-fd8129c6d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a804466-e05c-4f1c-b125-27f42336bc43",
   "metadata": {},
   "source": [
    "### Run an inference after fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40379bd4-c23d-4200-97f6-4c6317d6e2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4926b10d-41aa-463b-817e-dc924ab7d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"def hello_world():\"\n",
    "\n",
    "completion = model.generate(**tokenizer(text, return_tensors=\"pt\").to(\"cuda\"), max_length=100)\n",
    "\n",
    "print(tokenizer.decode(completion[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
